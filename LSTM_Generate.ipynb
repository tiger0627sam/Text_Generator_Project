{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5641,
     "status": "ok",
     "timestamp": 1652446990874,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "pPCmAo0Q_G3i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from opencc import OpenCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4454,
     "status": "ok",
     "timestamp": 1652447098041,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "YKiszF5doFGz",
    "outputId": "d0954123-aaaf-49fc-9598-dcc1ec6505c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 23:37:19.286688: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-12-09 23:37:19.286712: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-09 23:37:19.286716: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-09 23:37:19.286746: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-09 23:37:19.286760: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# switch model\n",
    "model = tf.keras.models.load_model('./Model/LSTM_OpLabV2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652447020633,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "6LP0BwFDAmcS",
    "outputId": "a082dad7-3cd9-4910-b24a-911a0f039b9f"
   },
   "outputs": [],
   "source": [
    "# 文字轉數字(index)\n",
    "with open('./Model/LSTM_OpLabV2_dic.json', 'r', encoding='utf-8') as fileRead:\n",
    "        word2Index = json.load(fileRead)\n",
    "index2Word = {word2Index[word]:word for word in word2Index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652449863952,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "b3ryhOIg4-qB"
   },
   "outputs": [],
   "source": [
    "# 預測文字，並把預測文字循環當作下一次的輸入\n",
    "\n",
    "# 設定你的temperature\n",
    "temperature = 0.005\n",
    "seq_len = 100\n",
    "\n",
    "def generateWords(input,words=5, wordCount=100):\n",
    "    paragraph = \"\"\n",
    "    for ind in input:\n",
    "        paragraph += index2Word[ind]\n",
    "        \n",
    "    while words>0 and len(paragraph) < wordCount:\n",
    "        next_input = tf.expand_dims(input,axis=0)\n",
    "        predicts = model(next_input)\n",
    "        predicts = predicts[:,-1,:]\n",
    "        predicts /= temperature\n",
    "        result = tf.random.categorical(\n",
    "            predicts,num_samples=1\n",
    "        )\n",
    "        chinese_ind = tf.squeeze(result).numpy()\n",
    "        # print(index2Word[chinese_ind],end=\"\")\n",
    "        paragraph += index2Word[chinese_ind]\n",
    "        input = input+[chinese_ind]\n",
    "        input = input[-seq_len:]\n",
    "        if index2Word[input[-1]] == \"。\":\n",
    "            words -=1\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44290,
     "status": "ok",
     "timestamp": 1652449908233,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "l7ELuAjW3rKW",
    "outputId": "3c93e08c-8a95-4efc-8684-1deb28bd4b79"
   },
   "outputs": [],
   "source": [
    "cc = OpenCC('t2s')\n",
    "init_seq = cc.convert(\"有鬼靠\")\n",
    "init_seq_ind = [word2Index[w] for w in init_seq]\n",
    "input = init_seq_ind[-seq_len:]\n",
    "\n",
    "result = generateWords(input,20,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'有鬼靠近。”“那你说说，你们看看我们……”“什么？”“我们是来找你的。”“那你们……”“我们是来找你的，我们是来找你的。”“那你们……”“我们是来找你的，你们是不是在这里？”“我们是来找你的。”“那你们……”“我们是来找你的，我们的孩子，你们不要走，我们不要走，我们就不要走了。”“那你们怎么了？”“我们是不是走错路了？”“我们是不是走错路了？”“我们是不是有些不对劲了，你们不要走，我们就不能再走了。”“那么，你们不要走，我们不要走，我们就不会再来了。”“那怎么办？”“我们是不是走错路了？”“我们是不是走错路了？”“我们是不是有些不对劲，你们不要走，我们不要走，我们就不会再来了。”“那你们怎么走了？”“我们是不是走错路了？”“我们是不是有些不对劲，你们不是说好了吗？”“不，我们不是人，是鬼！”“我们是不是有些不对劲，你们不是说好了，你们不要走，我们不要走，我们就不会再来了。”“那你们怎么不去上班？”“我们是来找你的。”“那你们怎么不去上班？”“我们是来找你的。”“那你们怎么不去上班？”“我们是来找你的。”“那你们怎么不去上班？”“我们是来找你的。”“那你们怎么不去上班？”“我们是来找你的。”“那你们……”“我们是来找你的，你们是不是在这里？”“我们是来找你的。”“那你们……”“我们是来找你的。”“那你们怎么不去上班？”“我们是来找你的。”“那你们怎么不去上班？”“我们是来找你的。”“那你们怎么不去上班？”“我们是来找你的。”“那你说说，你们是不是在这里？”“我们是来找你的。'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.count(\"。\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TextGeneration_108403547.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "IR-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
