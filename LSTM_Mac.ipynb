{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5641,
     "status": "ok",
     "timestamp": 1652446990874,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "pPCmAo0Q_G3i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strQ2B(ustring):\n",
    "    \"\"\"把字串空格全形轉半形\"\"\"\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全形空格直接轉換\n",
    "                inside_code = 32\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = './Data/Origin/'\n",
    "files = os.listdir(dataPath)\n",
    "allContent = ''\n",
    "for file in files:\n",
    "    tempFileJSON = json.load(open(dataPath + file, 'r', encoding='utf-8'))\n",
    "    tempContent = tempFileJSON['Context']\n",
    "    tempText = strQ2B(tempContent).replace(' ','').replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "    tempText = re.sub('[★_-]', \"\", tempText)\n",
    "    allContent += tempText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652446990874,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "1Mbvzh_9_Tz8",
    "outputId": "ba705564-d18a-4657-f54f-0d9ffeb88c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 10952516\n",
      "包含了5889 個獨一無二的字 (含標點符號)\n",
      "\n",
      "太平间里的歌声某市医院太平间突然传来了一阵歌声！那是因为一个女人在里面，女人为什么会在里面！？那是因为一个女人在里面，女人为什么会在里面！？那是因为她已经......夜已经很深了，今天是小琳值班，她看了看表，十二点整。“很晚了，快睡吧。”她整理了一下床铺，顺手把看了一半的小说放到办公桌上，就在这个时候，忽然的，灯灭了，这个城市没有别的特点只是在每天的十二点以后开始停电，一直停到第二天早晨六点。正因为这样，所以一到午夜，黑暗就会笼罩整个城市，大街上也不会有一个行人，看上去就像座，鬼城！小琳是个胆子很大的女孩子，可是，她始终是个女孩，是女孩对黑暗都会有一定的恐惧。她自然不会是例外。战战兢兢的爬到了床上，她急忙用被子蒙住了头。也不知过了多长时间，正当小琳迷迷胡胡的刚刚要睡着的时候，一阵动听却又哀伤的歌，传到了她的耳里，在这黑暗的环境，而且还是在寂静的医院里，这么深的夜，有谁会唱歌呢？歌声越来越急促，把小琳吵醒了，这哀怨的歌，好像在对她说：“来吧！来我这里，来听我唱歌！”小琳是个嗜乐狂，她的理想就是要做个乐手，无奈她的家人，没有一个同意的，强迫性的，把她送到护士学校。因为他们相信，无论任何时候，学医都不会失业。这歌声听得小琳心痒难熬，我敢说，无论是谁，在这种诡异的情况下都有不会有想去看看到底谁在唱歌的。可小琳一定会是个例外，因为她太喜爱音乐了，听到这么动听的歌，她当然要一窥究竟了，虽然现在是午夜，虽然现在是漆黑一片，虽然伸手不见五指。于是，她拧亮了手电筒，披了件衣服，推开了值班室的门。门刚被推开，一阵陰风迎面扑了过来。医院里就算是白天也是陰森森的，更何况现在是午夜，而且又没有电！走在这空旷的走廊里，唯一的光明只是小琳手中的手电筒所发出的昏黄的灯光，她心里真是发毛，周围静的叫人发慌，甚至能听到心跳的声音。整幢大楼，只有那歌声，和小琳脚上的高跟鞋撞击地面的声音。医院是座八层楼的建筑，小琳的值班室在三楼，她边走边向前看了看，走廊尽头的转角，就是通往二楼的楼梯。“歌声一定是一楼发出来的。”小琳就这样想着，边左顾右盼的下到二楼。她真怕忽然间从陰暗的角落钻出个什么怪物！二楼的走廊尽头才是通往一楼的楼梯，小琳不禁抱怨：“建楼的单位是怎么想的，平时还以为隔层楼一个楼梯挺好玩，可是现在才觉得，原来这么搞，要多走多少冤枉路哇！”看到那长长的走廊，小琳真想就此放弃，回值班室里一觉到天明。可是，好\n"
     ]
    }
   ],
   "source": [
    "contentLength = len(allContent)\n",
    "uniqueWords = set(allContent)\n",
    "print(f\"total: {contentLength}\")\n",
    "print(f\"包含了{len(uniqueWords)} 個獨一無二的字 (含標點符號)\\n\")\n",
    "print(allContent[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1652446991331,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "tQDQ8hxBEa6d"
   },
   "outputs": [],
   "source": [
    "# 計算字數統計\n",
    "wordsCount = {}\n",
    "for w in allContent:\n",
    "    if w in wordsCount:\n",
    "        wordsCount[w] += 1\n",
    "    else:\n",
    "        wordsCount[w] = 1\n",
    "\n",
    "wordsCount = sorted(wordsCount.items(),key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1652446991331,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "VT90O679Fe0T",
    "outputId": "ea6d0a78-4e29-4b72-9a38-d1ed20784781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1439\n",
      "['蓖', '褔', '徳', '囯', '禇', '濮', '唛', '鹗', '幪', '荍', '瓿', '枸', '‵', '′', '滾', '牴', '脫', '竦', '△', '塺', '烝', '溏', '進', '鮈', '扽', '桖', '馑', '査', '裏', '臻', '礞', '诨', '伛', '酢', '強', '芧', '訢', '昇', '皲', '鳗', 'ヽ', '冼', '蓐', '氽', '∧', '宓', '隹', '阋', 'г', '砹', '畲', 'Α', '姌', '趸', 'ǒ', '颍', '琛', '汴', '樯', '躱', '説', '褍', '￼', '耔', '喺', '癜', '岱', '埙', '叕', '捥', '乿', '郏', '庑', '囟', '孖', '鄍', '锊', '莿', '冄', '囿', '爙', '訴', '溼', '銭', '彳', '烽', '疦', '斛', '踡', '噁', '蚰', '牾', '涘', '渤', '跘', '懞', '〈', '〖', '〗', '戰', '軍', '衛', '邙', '庖', '彊', '崚', '麾', '萸', '孢', '踔', '谵', '怙', '悛', '滇', '棧', '摃', '鹩', '涑', '冇', '蛞', '蝓', '〕', '簦', '妽', '嫠', '哕', '娈', '诹', '徼', '牗', '麂', '缍', '紗', '诟', '蓆', '缳', '岬', '酰', '岵', '耆', '鲸', '甯', '搛', '蠛', '桡', '镗', '汊', '爍', '缽', '罰', '數', '寫', '慄', '馱', '笄', '鸢', '臬', '颉', '绀', '擢', '啁', '嗌', '溧', '負', '勝', '畚', '稞', '鲛', '沬', '°', '麿', '陂', '狍', '吣', '弼', '彘', '寤', '艄', '鑵', '垅', '懣', '椹', '葚', '邈', '镬', 'ā', '箪', '崂', '№', '語', '遠', '惝', '畿', '阊', '闾', 'í', '赅', '铩', '⒃', '筮', '羲', '檄', '晣', '匈', '蠖', '﹒', '鹳', '幛', '芪', '滗', '砗', '貉', '奌', '歺', '龍', '呋', '擘', '釚', '掍', '毖', '寮', '嵬', '噏', '臟', '偱', '箥', '瞍', '岫', '辎', '蝥', '卞', '碓', '翦', '圊', '倮', '噍', '駕', '掤', '祜', '蜮', '彀', '圹', '蝹', 'ū', '缛', '刬', '钨', '眊', '裉', '痱', '妊', '娠', '箓', '绌', '坂', '掛', '绐', 'ㄠ', '厣', '逵', '仳', '秿', '仞', '\\x08', '聞', '耖', '瀵', '俅', '漬', '裝', '氮', '歆', '醴', '螯', '镲', '鞑', '陴', '汆', '嘙', '忭', '鸶', '秕', 'Ⅱ', '﹐', '﹑', '﹗', '闵', '蚜', '娉', '苕', '牍', '溻', '﹏', '跣', '蚍', '蜉', '鸱', '孳', '涪', '＠', '♀', '傑', '暼', '•', '嘇', '萻', '鄳', '畋', '煱', '浲', '鐏', '砻', '飧', '伧', '晳', '內', '帙', '疴', '彔', '糥', '氨', '嘌', '鬃', '秣', '邕', '缧', '袈', '裟', '瘳', '帯', '佷', '陉', '箬', '裰', '臌', '筢', '愰', '壅', '赿', '钏', '桷', '屄', '媲', '湫', '缶', '裨', '詈', '↖', '嫫', '幓', '砭', '焀', '咹', '忾', '铙', '锴', '髫', '咵', '狯', '潞', '螟', '糅', '肏', '醛', '溷', '枊', '暹', '螓', 'Ｃ', '枰', '憟', '澶', '廪', '蚨', '慝', '蓊', '呴', '醧', '龃', '龉', '莠', '凫', '龅', '脍', '呰', '尥', '黔', '袼', '褙', '疡', '柚', '疟', '朣', '紮', '岙', '荇', '夼', '熘', '钤', '㔾', '犍', '挈', '浯', '碘', '垓', '窨', '橛', '砟', '酎', '钡', '尙', '猷', '戆', '棼', '悱', '竽', '潍', '眙', '鈅', '帼', '仫', '螫', '觌', '讼', '赑', '屃', '墒', '踼', '費', '勁', '讦', '\\ue2e5', '绶', '嬾', '滲', '揾', '厩', '嬅', '妁', '毽', '舂', '磔', '缡', '蕖', '徂', '馓', '喱', '莜', 'ㄧ', '莅', '\\ue0e5', '\\ue063', '逭', '椄', '谖', '宄', '嫒', '荩', '豢', '袷', '甑', 'ㄊ', '胪', '鞯', '┧', '摺', '郷', '塲', '蒯', '偁', '僖', '襻', '薹', '檎', '栲', '餬', '雃', '賓', '圏', '車', '欸', '碛', 'Ｖ', 'ｂ', 'ｈ', '殭', '睚', '婵', '灏', '祉', '嵫', '菟', '芫', '俦', '谳', '蘅', '鳟', '捩', '愆', '＝', '彝', '醭', '螅', '卮', '鞲', '阌', '篌', 'ヒ', 'ё', '篁', '诖', '埽', '猓', '鼋', '媸', '淦', '陔', '悃', '珞', '約', '煺', '啉', '誰', '蜱', '潋', '滟', '鬏', '踅', '呔', 'Ｎ', 'Ｆ', '饬', '顔', '踊', '铰', '⑿', '⒀', '⒁', '⒂', '⒄', '⒅', '⒆', '⒇', '芘', '晢', '抔', '酡', '┅', '鬈', '鲇', '唦', '桎', '梏', '溲', '豉', '粝', '拊', '枇', '抺', '橹', '棹', '遴', '○', '箅', '馐', '躶', '馔', '跻', '泅', '瞭', '涿', '淄', '骟', '塚', '闱', '鲠', '癣', '皋', '秫', '佉', '尜', '耨', '炝', '汞', '瘮', '讴', '畀', '瘗', '淙', '焙', '箴', '札', '亍', '／', '笞', '锱', '铢', '搦', '嫋', '鬻', '诣', '蒹', '葭', '柑', '瓠', '攮', '鬯', '衾', '撷', '〉', '雎', '愍', '髹', '纾', '庠', '椿', '睥', '鄹', '眄', '←', '濛', '晤', '藐', '溚', '璞', '玮', '瞽', '訶', '溽', '掊', '弁', '咤', '｀', '簾', '轼', '镢', '遅', 'す', 'ぎ', 'か', 'が', 'と', 'ど', '黙', 'っ', 'の', 'み', 'し', 'い', 'サ', 'イ', 'ン', '嘡', '浠', '衢', '曛', '槎', '菏', '郓', '↓', '↑', '浒', '蕨', '榫', '暝', '骊', '砬', '沪', '绥', '裌', '痿', '戌', '钹', '慥', '蹁', '跹', '埔', '鞣', '逶', '炤', '燠', '傈', '豌', '吔', '奁', '殍', '呡', '蓍', '赭', '洌', '嵊', '嗄', '硪', '笊', '翮', '呑', '來', '僮', '鳃', '熹', '怄', '粕', '鹭', '舶', '垩', '昴', '唑', '铬', '硄', '⊙', 'Ｅ', '＾', '茴', '衮', '鋈', '泾', '昽', '菘', '氯', 'ｐ', '焯', '鳜', '玺', '嗐', '悭', '儋', '蝨', '砵', '邳', '樨', '肄', '螈', '浚', '豕', 'Ｄ', 'Ｒ', 'Ｑ', '讓', '钿', '嬛', '瘢', '焗', '妗', '珅', '膑', '徕', '菽', '桫', '蹓', '鸩', '虱', '鹞', '柰', '啭', '蔌', '娲', '僳', '俚', '诰', '佞', '哏', '缟', '彿', '疽', '酶', '柒', '俸', '浣', '裏', '挻', '珲', '樽', '蚩', '炁', '鳌', 'Ｔ', '渏', '薜', '睢', '荚', '晷', '荸', '荠', '榖', '隽', '嵴', '劁', '宪', '菖', '呶', '谚', '娣', '芍', '⑤', '⑥', '⑦', '⑧', '⑨', '⑩', '⑾', '骥', 'ｏ', '祺', '圜', '堑', '煨', '锏', '蝾', '蔗', '杷', '％', '々', '嶂', '淩', '訇', '岀', '湓', '刍', '抨', '蝼', '瓤', '胤', '汾', '悌', 'Ｂ', '绡', '讧', '箸', '睇', '磺', '氅', '眇', '仟', '谀', '邯', '郸', '岿', '稷', '黒', '崛', '泸', '\\x18', '遒', '囹', '圄', '皖', '摈', '翳', '戊', '弭', '扞', '铧', '磐', '無', '盧', '薩', '淖', '鲫', '敖', '荟', '屐', 'Ｍ', 'さ', '叻', '煜', '橄', '觐', '嗉', '罅', '→', 'ㄡ', '肱', '倷', '谥', '椤', '緾', '飚', '氢', '贲', '箫', '鹄', '跐', '浭', '沤', '徵', '錾', '捍', '℃', '诿', '跗', '懿', '酞', '瘊', '陲', '胱', '埸', '妣', '獭', '睃', '敕', '傧', '侩', '鹫', '牠', 'Ｏ', 'Ｉ', '蛎', '糨', '蝌', '蚪', '潲', '–', '粲', '橼', '●', '槃', '蟠', '徜', '缙', '圮', '诮', '缱', '睾', '銮', '赈', '＇', '珰', '焐', '饯', '膻', '蛔', '嫰', '杼', '妲', 'ǐ', '讫', '蟮', 'π', '斡', '壬', '铆', '〔', '弑', '髙', '①', '②', '③', '④', 'ｒ', '哚', '贻', '纡', '蘼', '篑', '哂', '邑', '伢', '峒', '藩', '\\\\', '螳', '胰', '鎏', '齑', '谝', '沒', '蜇', '恫', '谪', '愎', '泫', '〃', '渭', '轶', '闍', '桉', '蓟', '赣', '疱', '绉', '帔', '斫', '吒', '徙', '绦', '鎝', '咁', '撴', '恚', '呖', '悖', '耒', '诳', '锲', '嗳', '乜', '喑', '猢', '狲', '媤', '痫', '弈', 'た', 'き', '锺', '飨', '膳', '榄', '┌', '┐', 'ㄎ', '啻', '禳', '瓒', '嵇', '腱', '胄', '韪', '澹', '抟', '遨', '腩', '酉', '癒', '榈', '酚', '畦', '舛', '嬲', '戍', '亟', '隼', '蒽', '酋', '癯', '氟', '擤', '淛', '萁', '媾', '炀', '滕', '僭', 'ｍ', '胼', '丕', '夔', '茏', '傣', '喟', '筌', '洱', '苪', '勳', '镔', '哙', '貂', '躅', '爿', '痍', 'Ｌ', 'Ｐ', '昙', '鳏', '臜', '鼬', '疖', '绻', '晩', '倨', '瘙', '蜍', '驷', '佃', '揿', '罂', '忱', '吽', '缒', '埠', '殚', '笈', '刎', '饴', '痂', '洮', '囧', '姹', '毂', '哔', '麓', '遽', '腴', '阄', '诽', '倭', '偈', '菅', '阐', '纣', '镁', '劾', '叟', '硅', 'Ｇ', '俎', '氖', '蚤', '釜', '褡', '裢', '阙', '鸹', '歼', '痈', '铤', '渥', '戗', '棣', '囉', '骛', '绮', '伥', 'ㄌ', '檩', '焖', '┬', '┘', '└', '┴', '徇', '柘', 'ｘ', '贰', '儆', '崃', '蹼', '篦', '骘', '熨', '揎', '暨', '榛', '鲈', '纂', '菓', '黧', '灸', '醚', '垭', '圪', '巽', '椽', '䦆', '湟', '轲', '薨', '箝', '＋', '踯', '煅', '杞', '祇', '黍', '宕', '曷', '瑚', '腭', '犷', '橇', '烩', '骜', '蟾', '潼', '玳', '噻', '鹌', '旌', '刈', '钎', '雹', '鹜', '镪', '濯', '谒', '嵘', '嫡', '裱', '酪', '茕', '耘', '鳄', '掴', '卅', '奓', '痢', '勋', '蜢', '屙', '诏', '谏', '诓', '栉', '戎', '吡', '倆', '谆', '涝', '蕙', '罄', '叁', '懔', '阆', 'も', '嫔', '魃', '镂', '┤', '狺', '堋', '豺', '旖', '旎', '铻', '噘', '邛', '噹', '羚', '珺', '狒', '吥', '钾', '姝', '猞', '猁', '闫', '纰', '缜', '迩', '糁', '煳', '诠', '蹰', '馀', '跎', '舷', '唷', '赁', '糜', 'Ｋ', 'ｉ', 'ｔ', 'ｅ', '掼', '瑁', '忸', '怩', '鹑', '嗙', '筵', '妯', '娌', '璇', '矶', '殄', '巩', '舵', '礴', '聩', '貔', '貅', '骡', '椰', '蓑', '襄', '诙', '弩', '鸷', '厝', '爻', '耄', '耋', '篙', '靛', '矸', 'Ｈ', '鏖', '逑', '彗', '缢', '倜', '磙', '獐', '沂', '侗', '楔', '孵', '廿', '鸠', '倌', 'ㄟ', '夥', '胺', '铂', '├', '嗟', '咭', '冕', '桅', '霭', '闰', '氐', '铣', '蛹', '餮', '衿', '褒', '颂', '皴', '踟', '唁', '浜', '抒', '阡', '驹', '泱', '颦', '鏊', '镑', '噫', '赧', '驽', '帛', '渚', '砥', '葆', '莘', '奂', '逡', '牯', '瀚', '弋', '镌', '虬', '闽', '剽', '雌', '踽', '赝', '寅', '妳', '谗', '谤', '墀', '薅', '稔', '牒', '喙', '诘', '啖', '珈', '薏', '巅', '篾', '糗', '跶', '迄', '眦', '阕', '铡', '汲', '纫', '泓', '纨', '绔', '哞', '嘬', '蛟', '汛', '┼', '帏', '锛', '麸', '蒌', '〇', '圭', '饽', '嬷', '勐', '箔', '拚', '嘹', '捯', '锒', '唳', '募', '颔', '酵', '搽', '痨', '﹕', '铠', '戟', '豚', '颀', '舰', '瘴', '笤', '牟', '伉', '俪', '饷', '镚', '淆', '堰', '遑', '髯', '蚱', '阒', '筠', '恁', '矜', '阉', '漕', '阜', '诋', '醍', '醐', '袤', '蚺', '陇', '翀', '淬', '峪', '亥', '笸', '埕', '庾', '旸']\n"
     ]
    }
   ],
   "source": [
    "notFrequentWordsCount = 10\n",
    "notFrequentWords = [_[0] for _ in wordsCount if _[1]<notFrequentWordsCount]\n",
    "print(f\"{len(notFrequentWords)}\")\n",
    "print(notFrequentWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29305,
     "status": "ok",
     "timestamp": 1652447020633,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "e_uP5gOVIy2K",
    "outputId": "cbb8f0b3-166b-473a-eb63-c011dee64d58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin length 10952516\n",
      "去除不常出現的文字後\n",
      "剩餘10947965個字\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'太平间里的歌声某市医院太平间突然传来了一阵歌声！那是因为一个女人在里面，女人为什么会在里面！？那是因为一个女人在里面，女人为什么会在里面！？那是因为她已经......夜已经很深了，今天是小琳值班，她看了看表，十二点整。“很晚了，快睡吧。”她整理了一下床铺，顺手把看了一半的小说放到办公桌上，就在这个时候，忽然的，灯灭了，这个城市没有别的特点只是在每天的十二点以后开始停电，一直停到第二天早晨六点。正因为这样，所以一到午夜，黑暗就会笼罩整个城市，大街上也不会有一个行人，看上去就像座，鬼城！小琳是个胆子很大的女孩子，可是，她始终是个女孩，是女孩对黑暗都会有一定的恐惧。她自然不会是例外。战战兢兢的爬到了床上，她急忙用被子蒙住了头。也不知过了多长时间，正当小琳迷迷胡胡的刚刚要睡着的时候，一阵动听却又哀伤的歌，传到了她的耳里，在这黑暗的环境，而且还是在寂静的医院里，这么深的夜，有谁会唱歌呢？歌声越来越急促，把小琳吵醒了，这哀怨的歌，好像在对她说：“来吧！来我这里，来听我唱歌！”小琳是个嗜乐狂，她的理想就是要做个乐手，无奈她的家人，没有一个同意的，强迫性的，把她送到护士学校。因为他们相信，无论任何时候'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"origin length {contentLength}\")\n",
    "print(f\"去除不常出現的文字後\")\n",
    "for removeWord in notFrequentWords:\n",
    "    allContent = allContent.replace(removeWord, '')\n",
    "uniqueWords = set(allContent)\n",
    "print(f\"剩餘{len(allContent)}個字\")\n",
    "allContent[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652447020633,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "6LP0BwFDAmcS",
    "outputId": "a082dad7-3cd9-4910-b24a-911a0f039b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文字 : \n",
      "太平间里的歌声某市医院太平间突然传来了一阵歌声！那是因为一个女人在里面，女人为什\n",
      "轉成index : \n",
      "{2948, 3078, 1799, 2061, 660, 2455, 1687, 4379, 1192, 1582, 3502, 437, 3650, 835, 4295, 844, 2894, 1743, 4304, 1492, 2903, 4184, 1373, 2013, 2146, 3171, 4325, 1383, 106, 2805}\n"
     ]
    }
   ],
   "source": [
    "# 文字轉數字(index)\n",
    "word2Index = {word:index for index,word in enumerate(uniqueWords)}\n",
    "index2Word = {word2Index[word]:word for word in word2Index}\n",
    "\n",
    "content2Index = [word2Index[w] for w in allContent]\n",
    "\n",
    "print(\"原始文字 : \")\n",
    "print(allContent[:40])\n",
    "print(\"轉成index : \")\n",
    "print({word2Index[w] for w in allContent[:40]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1652447020633,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "H-KDv4kqgxLH"
   },
   "outputs": [],
   "source": [
    "def ind2word_seq(seq):\n",
    "    return [index2Word[i] for i in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4831,
     "status": "ok",
     "timestamp": 1652447025461,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "_aDyjJymDmVv",
    "outputId": "fa1c548d-14d6-49be-fb55-d214fc54e236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31,)\n",
      "tf.Tensor(\n",
      "[1492  660 2146 2805  437 2894 1582 1799 3171 1373 2948 1492  660 2146\n",
      "  106  844 1743 1192 4304 4379 2903 2894 1582 4184 3650 3078 2455 1687\n",
      " 4379 2061 2013], shape=(31,), dtype=int32)\n",
      "['太', '平', '间', '里', '的', '歌', '声', '某', '市', '医', '院', '太', '平', '间', '突', '然', '传', '来', '了', '一', '阵', '歌', '声', '！', '那', '是', '因', '为', '一', '个', '女']\n",
      "(31,)\n",
      "tf.Tensor(\n",
      "[1383 4325 2805  835 3502 2013 1383 1687 4295 4002 2722 4325 2805  835\n",
      " 4184 1968 3650 3078 2455 1687 4379 2061 2013 1383 4325 2805  835 3502\n",
      " 2013 1383 1687], shape=(31,), dtype=int32)\n",
      "['人', '在', '里', '面', '，', '女', '人', '为', '什', '么', '会', '在', '里', '面', '！', '？', '那', '是', '因', '为', '一', '个', '女', '人', '在', '里', '面', '，', '女', '人', '为']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 10:17:50.486499: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-12-08 10:17:50.486522: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-08 10:17:50.486528: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-08 10:17:50.486557: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-08 10:17:50.486571: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 設定輸入模型長度\n",
    "seq_len = 30\n",
    "characters = tf.data.Dataset.from_tensor_slices(content2Index)\n",
    "\n",
    "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(2):\n",
    "    print(seq.shape)\n",
    "    print(seq)\n",
    "    print([index2Word[i] for i in seq.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1652447025461,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "jhFC16MdLONw",
    "outputId": "e786c858-0952-4e1f-cedf-e1c78acbe9bb"
   },
   "outputs": [],
   "source": [
    "# 做input、target切割\n",
    "def split_input_target(seq):\n",
    "    input_txt = seq[:-1]\n",
    "    target_txt = seq[1:]\n",
    "    return input_txt,target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1652447025990,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "qnJ4Bdj2gZ1V",
    "outputId": "39a7de28-ddd6-48f4-ed04-215b20d43c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : ['太', '平', '间', '里', '的', '歌', '声', '某', '市', '医', '院', '太', '平', '间', '突', '然', '传', '来', '了', '一', '阵', '歌', '声', '！', '那', '是', '因', '为', '一', '个']\n",
      "Target: ['平', '间', '里', '的', '歌', '声', '某', '市', '医', '院', '太', '平', '间', '突', '然', '传', '来', '了', '一', '阵', '歌', '声', '！', '那', '是', '因', '为', '一', '个', '女']\n",
      "--------------------------------------------------\n",
      "Input : [1492  660 2146 2805  437 2894 1582 1799 3171 1373 2948 1492  660 2146\n",
      "  106  844 1743 1192 4304 4379 2903 2894 1582 4184 3650 3078 2455 1687\n",
      " 4379 2061]\n",
      "Target: [ 660 2146 2805  437 2894 1582 1799 3171 1373 2948 1492  660 2146  106\n",
      "  844 1743 1192 4304 4379 2903 2894 1582 4184 3650 3078 2455 1687 4379\n",
      " 2061 2013]\n"
     ]
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "for input_example,target_exaple in dataset.take(1):\n",
    "    print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
    "    print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Input :\", input_example.numpy())\n",
    "    print(\"Target:\", target_exaple.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1652447025990,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "UNivSh2Igr2-",
    "outputId": "3d39c499-dc23-4307-d16d-e770d72f3c94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(128, 30), dtype=tf.int32, name=None), TensorSpec(shape=(128, 30), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立資料集\n",
    "# Batch size\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67611,
     "status": "ok",
     "timestamp": 1652447093595,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "UkRcSZAHnxlk",
    "outputId": "decb5171-3c95-4ef5-b398-3b2a3541aa21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         569600    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 1024)        4722688   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 512)         3147776   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 4450)        2282850   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10722914 (40.90 MB)\n",
      "Trainable params: 10722914 (40.90 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 超參數\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(\n",
    "  tf.keras.layers.Embedding(\n",
    "    input_dim=len(uniqueWords), \n",
    "    output_dim=EMBEDDING_DIM\n",
    "))\n",
    "\n",
    "model.add(\n",
    "  tf.keras.layers.LSTM(\n",
    "    units=1024, \n",
    "    return_sequences=True, \n",
    "))\n",
    "\n",
    "model.add(\n",
    "  tf.keras.layers.LSTM(\n",
    "    units=512, \n",
    "    return_sequences=True,\n",
    "))\n",
    "  \n",
    "model.add(\n",
    "  tf.keras.layers.Dense(\n",
    "      len(uniqueWords),activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4454,
     "status": "ok",
     "timestamp": 1652447098041,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "YKiszF5doFGz",
    "outputId": "d0954123-aaaf-49fc-9598-dcc1ec6505c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input shape : (128, 30)\n",
      "Model output shape : (128, 30, 4450)\n",
      "Model target shape : (128, 30)\n"
     ]
    }
   ],
   "source": [
    "# 查看模型的輸入、輸出 shape\n",
    "for input_example,target_exaple in dataset.take(1):\n",
    "    predict_example = model(input_example)\n",
    "    print(f\"Model input shape : {input_example.shape}\")\n",
    "    print(f\"Model output shape : {predict_example.shape}\")\n",
    "    print(f\"Model target shape : {target_exaple.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1652447098041,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "CsN6Zz4NReV4",
    "outputId": "0e397697-55b0-42cf-c88e-af600b44fe55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原本的中文字序列：\n",
      "地方，主人给修好后，则有银钱落在窗台上。给钱会比修房的花费多\n",
      "----------------------------------------\n",
      "輸入尚未訓練的model後獲得：\n",
      "\n",
      "茹褶酷爆咒咒垂垂垂垂垂垂垂垂磕磕磕忪忪舱PP※※※※※锅姜姜\n"
     ]
    }
   ],
   "source": [
    "print(\"原本的中文字序列：\")\n",
    "[print(index2Word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
    "print()\n",
    "print(\"-\"*40)\n",
    "print(\"輸入尚未訓練的model後獲得：\")\n",
    "print()\n",
    "\n",
    "predict_words = tf.math.argmax(predict_example[0],-1)\n",
    "[print(index2Word[ind],end=\"\") for ind in predict_words.numpy()]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652447098041,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "unPfQAQBonFj"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2764800,
     "status": "ok",
     "timestamp": 1652449862836,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "5IW5xiiMpJhJ",
    "outputId": "d091f5ab-d2d3-4a23-92b6-7cc306335a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2759/2759 [==============================] - 250s 90ms/step - loss: 5.8094\n",
      "Epoch 2/20\n",
      "2759/2759 [==============================] - 253s 91ms/step - loss: 5.1371\n",
      "Epoch 3/20\n",
      "2759/2759 [==============================] - 249s 90ms/step - loss: 4.7365\n",
      "Epoch 4/20\n",
      "2759/2759 [==============================] - 246s 89ms/step - loss: 4.4906\n",
      "Epoch 5/20\n",
      " 925/2759 [=========>....................] - ETA: 2:43 - loss: 4.3733"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 前面使用 tf.data 建構的資料集\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/engine/training.py:1789\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1787\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1788\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1789\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/tensorflow/python/util/nest.py:629\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    545\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/tensorflow/python/util/nest_util.py:1168\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1170\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/tensorflow/python/util/nest_util.py:1208\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1204\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1207\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1208\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1209\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1210\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/tensorflow/python/util/nest_util.py:1208\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1203\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1204\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1207\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1208\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1209\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1210\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:396\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/anaconda3/envs/forTensorflow/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:362\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    361\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    dataset, # 前面使用 tf.data 建構的資料集\n",
    "    epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1652449862837,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "xxbK80fXpOWD",
    "outputId": "ec8440a0-18a9-4090-d493-71737e2df866"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1652449863952,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "A3elbMNg4z4N",
    "outputId": "7528a5a6-253d-4042-f0b0-e343d0117865"
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, \"./Model/LSTMV2\")\n",
    "after_train_predictions = model(input_example)\n",
    "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
    "\n",
    "print(\"原本的中文字序列：\")\n",
    "[print(index2Word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
    "print()\n",
    "print(\"-\"*40)\n",
    "print(\"輸入進訓練後的model後獲得：\")\n",
    "print()\n",
    "\n",
    "[print(index2Word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652449863952,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "b3ryhOIg4-qB"
   },
   "outputs": [],
   "source": [
    "# 預測文字，並把預測文字循環當作下一次的輸入\n",
    "\n",
    "# 設定你的temperature\n",
    "temperature = 0.01\n",
    "\n",
    "def generateWords(input,words=500):\n",
    "    [print(index2Word[ind],end=\"\") for ind in input]\n",
    "    for i in range(words):\n",
    "        next_input = tf.expand_dims(input,axis=0)\n",
    "        predicts = model(next_input)\n",
    "        predicts = predicts[:,-1,:]\n",
    "        predicts /= temperature\n",
    "        result = tf.random.categorical(\n",
    "            predicts,num_samples=1\n",
    "        )\n",
    "        chinese_ind = tf.squeeze(result).numpy()\n",
    "        print(index2Word[chinese_ind],end=\"\")\n",
    "        input = input+[chinese_ind]\n",
    "        input = input[-seq_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencc import OpenCC\n",
    "cc = OpenCC('t2s')\n",
    "init_seq = cc.convert(\"鬼\")\n",
    "init_seq_ind = [word2Index[w] for w in init_seq]\n",
    "input = init_seq_ind[-seq_len:]\n",
    "\n",
    "for i in range(1):\n",
    "        next_input = tf.expand_dims(input,axis=0)\n",
    "        predicts = model(next_input)\n",
    "        print(predicts)\n",
    "        predicts = predicts[:,-1,:]\n",
    "        print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44290,
     "status": "ok",
     "timestamp": 1652449908233,
     "user": {
      "displayName": "547蘇勁安",
      "userId": "12901927310267751394"
     },
     "user_tz": -480
    },
    "id": "l7ELuAjW3rKW",
    "outputId": "3c93e08c-8a95-4efc-8684-1deb28bd4b79"
   },
   "outputs": [],
   "source": [
    "init_seq = cc.convert(\"鬼\")\n",
    "init_seq_ind = [word2Index[w] for w in init_seq]\n",
    "input = init_seq_ind[-seq_len:]\n",
    "\n",
    "generateWords(input,500)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TextGeneration_108403547.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
